{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/arunavkonwar/collab-files/master/taylor-swift-songs.txt\n",
      "172032/165625 [===============================] - 0s 1us/step\n",
      "180224/165625 [================================] - 0s 1us/step\n",
      "('Corpus length:', 165625)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'taylor-swift.txt',\n",
    "    origin='https://raw.githubusercontent.com/arunavkonwar/collab-files/master/taylor-swift-songs.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of sequences:', 55189)\n",
      "('Unique characters:', 57)\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('epoch', 1)\n",
      "Epoch 1/1\n",
      "55189/55189 [==============================] - 68s 1ms/step - loss: 2.2400\n",
      "--- Generating with seed: \"thought just maybe\n",
      "you belong with me?\n",
      "you belong with mei s\"\n",
      "('------ temperature:', 0.2)\n",
      "thought just maybe\n",
      "you belong with me?\n",
      "you belong with mei so stert that they that you wand thet that you wand they back they that you wand thet wand that that you wand fore\n",
      "that that you wand that you wand thet they they the plame there that you wand that you wand that you wand they you wand the gore\n",
      "and the pleat you wand thet you wand they stare\n",
      "so the gott you wand that you wand that you wething that you that the the gond thet you weed you wand they lo()\n",
      "('------ temperature:', 0.5)\n",
      "ng that you that the the gond thet you weed you wand they lovent you love\n",
      "you wand time and that thes?\n",
      "whith a dong\n",
      "therethed\n",
      "as heal you gatter\n",
      "if the dound\n",
      "as so call you\n",
      " of that lout\n",
      "that the know but you all whent at so the rome\n",
      "that as \n",
      "hould thought\n",
      "bouthing fore\n",
      "what thathing that wat hot thould me don't me\n",
      "that is a foresthe\n",
      "shere\n",
      "on that as love\n",
      "they baby dout you we gott your whore that thath me don't e of you love\n",
      "that you alling that you wand ()\n",
      "('------ temperature:', 1.0)\n",
      " thath me don't e of you love\n",
      "that you alling that you wand soudher ne the plottit?\n",
      "(to thidgitha wild pli't juss loss,\n",
      "i can't godtid\n",
      " hand\n",
      "your wast thousd thas ite but fuet werling gond\n",
      "it't loughtrleta horekiever\n",
      "of ohathels\n",
      "saaby, if and your\n",
      "i can't be\n",
      "if here\n",
      "ofd plitc it hathkernout me doh,\n",
      "cork, mo, sor fideed and you i' sey you\n",
      "arealk\n",
      "you keet if itnoight\n",
      "inda gest'red that mo disttallud th theritn\n",
      "that i'ls bettey aod thayn.\n",
      "and\n",
      "you gonnver\n",
      "for\n",
      "()\n",
      "('------ temperature:', 1.2)\n",
      " th theritn\n",
      "that i'ls bettey aod thayn.\n",
      "and\n",
      "you gonnver\n",
      "for\n",
      "thr go me\n",
      "fro's\n",
      "thet?\n",
      "is lifs whatad\n",
      ", mont? or ghenky\n",
      "thaths\n",
      "us love\n",
      "the \n",
      "i't me do\n",
      "ldoto, gor\n",
      "in'th\n",
      "live ghas i cound, dret\n",
      " om wheny.\n",
      "boge\n",
      "thindath ghe'ls\n",
      "i'veatris\n",
      "and mees.unt\n",
      "weys, like\n",
      "thtary, whind nehs, pace lutt gost't wads\n",
      "\"pracks i con'te\n",
      "fout yevbrnd bimr nothknome, arenayo\n",
      "ist? cabr mhera's whay down..\n",
      "'la, sa's th\n",
      "louss, thats laye oo hoh\n",
      "(ip'st thrak\n",
      "hot\n",
      "you yeeccoy,\n",
      "i mack\n",
      "fout)\n",
      "s()\n",
      "('epoch', 2)\n",
      "Epoch 1/1\n",
      "55189/55189 [==============================] - 75s 1ms/step - loss: 1.7202\n",
      "--- Generating with seed: \"is one, babe\n",
      "this is the last time i'll ever call you, babe\n",
      "\"\n",
      "('------ temperature:', 0.2)\n",
      "is one, babe\n",
      "this is the last time i'll ever call you, babe\n",
      "the wind the wall you welling the wanting the wall you welling you welling the wall you welling the wall you want the wall you want the wall you welling the wall you want the wall you the hight the will she then you want you well me welling the wall you welling the wall you welling the wall you want the withing the wall you want the wanting the wall you want you welles i want the wanting the like ()\n",
      "('------ temperature:', 0.5)\n",
      "ng the wall you want you welles i want the wanting the like then i wanting you were then you want we welling then i gad i know you got wall me said the wall you got i'll me never get you never the with you welline you leve without you got we're like all be then i'll me thing i'm somes of thin i'll like of every remember we wad i live then i dan't leve with all you said this you meel thin like and yeally want, gave i'll got we're thing i'll be then the till()\n",
      "('------ temperature:', 1.0)\n",
      "yeally want, gave i'll got we're thing i'll be then the tillich you, know tim blactor i'll stors whore in weire that's i'd rell thing ever knoct & i minds me speckill\n",
      "held hat a pulpee i'm ever the hinds i'll deep knew the hightcressores\n",
      "agon't want you velper\n",
      "in you're thone i can tround call emye, i dan't gitright\n",
      "the his uld i can't wertalling is\n",
      "a shell chonga papolin\n",
      "an then?\n",
      "we'lline me were so you don't love with me, git mise wallhnd bage me, backin()\n",
      "('------ temperature:', 1.2)\n",
      " so you don't love with me, git mise wallhnd bage me, backing is live walllls so've girll kereme oh ald all\n",
      "new i sul , heam i can'll helep pid\"me we'd like agaaltell i rame se didrickist up thes thoup of we \"igh un elony hel, whlked acallayg't m daeplenttring is i'm belorgs on breke back leftrungs you's like this you lost\n",
      "fel croldy fo whall gance manded\n",
      "andund chand, is never gore\n",
      "'haus thoum i'l sware i knew puflig i daleloul hagen i'd is tolingstind go()\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 3):\n",
    "    print('epoch', epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
